{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "310bc9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fd6e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['N_Days', 'Status', 'Drug', 'Age', 'Sex', 'Ascites', 'Hepatomegaly',\n",
      "       'Spiders', 'Edema', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper',\n",
      "       'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin',\n",
      "       'Stage'],\n",
      "      dtype='object') Index(['N_Days', 'Status', 'Drug', 'Age', 'Sex', 'Ascites', 'Hepatomegaly',\n",
      "       'Spiders', 'Edema', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper',\n",
      "       'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('train_dataset.csv',index_col='ID')\n",
    "df1=pd.read_csv('test_dataset.csv',index_col='ID')\n",
    "print(df.columns, df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35f6c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "N_Days              0\n",
       "Status              0\n",
       "Drug             2025\n",
       "Age                 0\n",
       "Sex                 0\n",
       "Ascites          2246\n",
       "Hepatomegaly     2427\n",
       "Spiders          2590\n",
       "Edema               0\n",
       "Bilirubin           0\n",
       "Cholesterol      3101\n",
       "Albumin             0\n",
       "Copper           2156\n",
       "Alk_Phos         2498\n",
       "SGOT             2102\n",
       "Tryglicerides    2812\n",
       "Platelets         338\n",
       "Prothrombin       155\n",
       "Stage               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1d4775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Status', 'Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema'] ['N_Days', 'Status', 'Age', 'Sex', 'Edema', 'Bilirubin', 'Albumin']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols=list(df.select_dtypes(include=('object')).columns)\n",
    "continuous_cols=list(df.select_dtypes(include=(['int64', 'float64'])).columns)\n",
    "continuous_cols.remove(\"Stage\")\n",
    "non_null_cols=list(df.columns[df.notnull().all()])\n",
    "non_null_cols.remove(\"Stage\")\n",
    "print(categorical_cols,non_null_cols)\n",
    "sorted_null_cols=['Prothrombin', 'Platelets', 'Drug', 'SGOT', 'Copper', 'Ascites', 'Hepatomegaly', 'Alk_Phos', 'Spiders', 'Tryglicerides', 'Cholesterol']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26d975",
   "metadata": {},
   "source": [
    "### Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85050bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # replacing catagorical data with intigers in train data\n",
    "df['Sex'] = df['Sex'].replace({'M':0, 'F':1})                                # Male : 0 , Female :1\n",
    "df['Ascites'] = df['Ascites'].replace({'N':0, 'Y':1})                        # N : 0, Y : 1   \n",
    "df['Drug'] = df['Drug'].replace({'D-penicillamine':0, 'Placebo':1})          # D-penicillamine : 0, Placebo : 1   \n",
    "df['Hepatomegaly'] = df['Hepatomegaly'].replace({'N':0, 'Y':1})              # N : 0, Y : 1\n",
    "df['Spiders'] = df['Spiders'].replace({'N':0, 'Y':1})                        # N : 0, Y : 1\n",
    "df['Edema'] = df['Edema'].replace({'N':0, 'Y':1, 'S':-1})                    # N : 0, Y : 1, S : -1\n",
    "df['Status'] = df['Status'].replace({'C':0, 'CL':1, 'D':-1})                 # 'C':0, 'CL':1, 'D':-1\n",
    "\n",
    " # replacing catagorical data with intigers in test data\n",
    "df1['Sex'] = df1['Sex'].replace({'M':0, 'F':1})                                # Male : 0 , Female :1\n",
    "df1['Ascites'] = df1['Ascites'].replace({'N':0, 'Y':1})                        # N : 0, Y : 1   \n",
    "df1['Drug'] = df1['Drug'].replace({'D-penicillamine':0, 'Placebo':1})          # D-penicillamine : 0, Placebo : 1   \n",
    "df1['Hepatomegaly'] = df1['Hepatomegaly'].replace({'N':0, 'Y':1})              # N : 0, Y : 1\n",
    "df1['Spiders'] = df1['Spiders'].replace({'N':0, 'Y':1})                        # N : 0, Y : 1\n",
    "df1['Edema'] = df1['Edema'].replace({'N':0, 'Y':1, 'S':-1})                    # N : 0, Y : 1, S : -1\n",
    "df1['Status'] = df1['Status'].replace({'C':0, 'CL':1, 'D':-1})   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915b5da",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4558e486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N_Days              0\n",
       "Status              0\n",
       "Drug             2025\n",
       "Age                 0\n",
       "Sex                 0\n",
       "Ascites          2246\n",
       "Hepatomegaly     2427\n",
       "Spiders          2590\n",
       "Edema               0\n",
       "Bilirubin           0\n",
       "Cholesterol      3101\n",
       "Albumin             0\n",
       "Copper           2156\n",
       "Alk_Phos         2498\n",
       "SGOT             2102\n",
       "Tryglicerides    2812\n",
       "Platelets         338\n",
       "Prothrombin       155\n",
       "Stage               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1efbe53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Status</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N_Days</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>-0.035978</td>\n",
       "      <td>-0.069048</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>-0.031093</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>0.033535</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.045464</td>\n",
       "      <td>-0.028400</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>-0.011724</td>\n",
       "      <td>-0.022703</td>\n",
       "      <td>0.099012</td>\n",
       "      <td>0.042913</td>\n",
       "      <td>-0.006062</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>0.006840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013506</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>-0.012336</td>\n",
       "      <td>-0.020520</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>-0.010623</td>\n",
       "      <td>0.045075</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.022049</td>\n",
       "      <td>0.034721</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug</th>\n",
       "      <td>-0.035978</td>\n",
       "      <td>-0.013506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>-0.024106</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>-0.015001</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>-0.006536</td>\n",
       "      <td>-0.015917</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.051108</td>\n",
       "      <td>0.022982</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.069048</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>-0.010194</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>-0.035271</td>\n",
       "      <td>-0.011826</td>\n",
       "      <td>-0.043328</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>0.105258</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>-0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.013816</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.024106</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>-0.004399</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>-0.016111</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>-0.014293</td>\n",
       "      <td>-0.010295</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>-0.012433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ascites</th>\n",
       "      <td>-0.031093</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>-0.010194</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>-0.004148</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>-0.003345</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>-0.018179</td>\n",
       "      <td>-0.007914</td>\n",
       "      <td>-0.016884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <td>0.016119</td>\n",
       "      <td>-0.012336</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016257</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.044094</td>\n",
       "      <td>-0.005921</td>\n",
       "      <td>-0.018030</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>-0.007079</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>-0.020649</td>\n",
       "      <td>-0.022900</td>\n",
       "      <td>-0.004158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiders</th>\n",
       "      <td>0.033535</td>\n",
       "      <td>-0.020520</td>\n",
       "      <td>-0.015001</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.016257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006925</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>-0.010428</td>\n",
       "      <td>0.024053</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.013254</td>\n",
       "      <td>-0.028451</td>\n",
       "      <td>-0.009396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>-0.006925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.019649</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>-0.016123</td>\n",
       "      <td>-0.003993</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>-0.014821</td>\n",
       "      <td>-0.003061</td>\n",
       "      <td>-0.008758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilirubin</th>\n",
       "      <td>0.013037</td>\n",
       "      <td>-0.010623</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.062583</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.037234</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.010225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholesterol</th>\n",
       "      <td>0.045464</td>\n",
       "      <td>0.045075</td>\n",
       "      <td>-0.006536</td>\n",
       "      <td>-0.035271</td>\n",
       "      <td>-0.004399</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.044094</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-0.019649</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023670</td>\n",
       "      <td>-0.013332</td>\n",
       "      <td>-0.031814</td>\n",
       "      <td>0.020435</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>-0.017935</td>\n",
       "      <td>-0.012795</td>\n",
       "      <td>0.033273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albumin</th>\n",
       "      <td>-0.028400</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>-0.015917</td>\n",
       "      <td>-0.011826</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>-0.004148</td>\n",
       "      <td>-0.005921</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.062583</td>\n",
       "      <td>0.023670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>-0.039058</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>-0.012963</td>\n",
       "      <td>-0.015126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Copper</th>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>-0.043328</td>\n",
       "      <td>-0.016111</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>-0.018030</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>-0.016123</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>-0.013332</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.034465</td>\n",
       "      <td>-0.024679</td>\n",
       "      <td>-0.052658</td>\n",
       "      <td>-0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alk_Phos</th>\n",
       "      <td>-0.011724</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>-0.003345</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>-0.010428</td>\n",
       "      <td>-0.003993</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>-0.031814</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>-0.036749</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>0.040108</td>\n",
       "      <td>-0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGOT</th>\n",
       "      <td>-0.022703</td>\n",
       "      <td>0.022049</td>\n",
       "      <td>0.051108</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>-0.014293</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>-0.007079</td>\n",
       "      <td>0.024053</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>0.020435</td>\n",
       "      <td>-0.039058</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>0.059069</td>\n",
       "      <td>-0.029069</td>\n",
       "      <td>-0.017251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tryglicerides</th>\n",
       "      <td>0.099012</td>\n",
       "      <td>0.034721</td>\n",
       "      <td>0.022982</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>-0.010295</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>0.034465</td>\n",
       "      <td>-0.036749</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>0.016860</td>\n",
       "      <td>-0.043826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platelets</th>\n",
       "      <td>0.042913</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>0.105258</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.018179</td>\n",
       "      <td>-0.020649</td>\n",
       "      <td>-0.013254</td>\n",
       "      <td>-0.014821</td>\n",
       "      <td>-0.037234</td>\n",
       "      <td>-0.017935</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>-0.024679</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>0.059069</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>-0.021621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prothrombin</th>\n",
       "      <td>-0.006062</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>-0.007914</td>\n",
       "      <td>-0.022900</td>\n",
       "      <td>-0.028451</td>\n",
       "      <td>-0.003061</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.012795</td>\n",
       "      <td>-0.012963</td>\n",
       "      <td>-0.052658</td>\n",
       "      <td>0.040108</td>\n",
       "      <td>-0.029069</td>\n",
       "      <td>0.016860</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stage</th>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.026065</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>-0.012433</td>\n",
       "      <td>-0.016884</td>\n",
       "      <td>-0.004158</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>-0.008758</td>\n",
       "      <td>-0.010225</td>\n",
       "      <td>0.033273</td>\n",
       "      <td>-0.015126</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.017251</td>\n",
       "      <td>-0.043826</td>\n",
       "      <td>-0.021621</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 N_Days    Status      Drug       Age       Sex   Ascites  \\\n",
       "N_Days         1.000000  0.006840 -0.035978 -0.069048  0.013816 -0.031093   \n",
       "Status         0.006840  1.000000 -0.013506 -0.001128  0.001164  0.008727   \n",
       "Drug          -0.035978 -0.013506  1.000000  0.022108 -0.024106  0.009293   \n",
       "Age           -0.069048 -0.001128  0.022108  1.000000 -0.014149 -0.010194   \n",
       "Sex            0.013816  0.001164 -0.024106 -0.014149  1.000000  0.008337   \n",
       "Ascites       -0.031093  0.008727  0.009293 -0.010194  0.008337  1.000000   \n",
       "Hepatomegaly   0.016119 -0.012336  0.010275  0.007326  0.025391  0.004788   \n",
       "Spiders        0.033535 -0.020520 -0.015001 -0.029718  0.025404  0.016540   \n",
       "Edema          0.013727  0.005777  0.005933  0.006170  0.000761  0.001361   \n",
       "Bilirubin      0.013037 -0.010623  0.005009  0.017183 -0.006151 -0.004251   \n",
       "Cholesterol    0.045464  0.045075 -0.006536 -0.035271 -0.004399  0.011066   \n",
       "Albumin       -0.028400  0.001007 -0.015917 -0.011826  0.010137 -0.004148   \n",
       "Copper         0.008272  0.006169  0.016241 -0.043328 -0.016111  0.002621   \n",
       "Alk_Phos      -0.011724  0.023031  0.036587  0.014469  0.020542 -0.003345   \n",
       "SGOT          -0.022703  0.022049  0.051108  0.036427 -0.014293  0.004006   \n",
       "Tryglicerides  0.099012  0.034721  0.022982  0.032096 -0.010295  0.001957   \n",
       "Platelets      0.042913  0.003505  0.027758  0.105258 -0.000127 -0.018179   \n",
       "Prothrombin   -0.006062  0.001908 -0.000772  0.005112  0.006570 -0.007914   \n",
       "Stage          0.004066  0.026065  0.000584 -0.001854 -0.012433 -0.016884   \n",
       "\n",
       "               Hepatomegaly   Spiders     Edema  Bilirubin  Cholesterol  \\\n",
       "N_Days             0.016119  0.033535  0.013727   0.013037     0.045464   \n",
       "Status            -0.012336 -0.020520  0.005777  -0.010623     0.045075   \n",
       "Drug               0.010275 -0.015001  0.005933   0.005009    -0.006536   \n",
       "Age                0.007326 -0.029718  0.006170   0.017183    -0.035271   \n",
       "Sex                0.025391  0.025404  0.000761  -0.006151    -0.004399   \n",
       "Ascites            0.004788  0.016540  0.001361  -0.004251     0.011066   \n",
       "Hepatomegaly       1.000000  0.016257  0.010037   0.000823     0.044094   \n",
       "Spiders            0.016257  1.000000 -0.006925   0.021225    -0.009384   \n",
       "Edema              0.010037 -0.006925  1.000000   0.001000    -0.019649   \n",
       "Bilirubin          0.000823  0.021225  0.001000   1.000000     0.005986   \n",
       "Cholesterol        0.044094 -0.009384 -0.019649   0.005986     1.000000   \n",
       "Albumin           -0.005921  0.004038  0.005843   0.062583     0.023670   \n",
       "Copper            -0.018030  0.003506 -0.016123   0.001208    -0.013332   \n",
       "Alk_Phos           0.017047 -0.010428 -0.003993   0.040346    -0.031814   \n",
       "SGOT              -0.007079  0.024053  0.001269   0.020157     0.020435   \n",
       "Tryglicerides      0.008365  0.000085  0.015509  -0.009782     0.046358   \n",
       "Platelets         -0.020649 -0.013254 -0.014821  -0.037234    -0.017935   \n",
       "Prothrombin       -0.022900 -0.028451 -0.003061  -0.019610    -0.012795   \n",
       "Stage             -0.004158 -0.009396 -0.008758  -0.010225     0.033273   \n",
       "\n",
       "                Albumin    Copper  Alk_Phos      SGOT  Tryglicerides  \\\n",
       "N_Days        -0.028400  0.008272 -0.011724 -0.022703       0.099012   \n",
       "Status         0.001007  0.006169  0.023031  0.022049       0.034721   \n",
       "Drug          -0.015917  0.016241  0.036587  0.051108       0.022982   \n",
       "Age           -0.011826 -0.043328  0.014469  0.036427       0.032096   \n",
       "Sex            0.010137 -0.016111  0.020542 -0.014293      -0.010295   \n",
       "Ascites       -0.004148  0.002621 -0.003345  0.004006       0.001957   \n",
       "Hepatomegaly  -0.005921 -0.018030  0.017047 -0.007079       0.008365   \n",
       "Spiders        0.004038  0.003506 -0.010428  0.024053       0.000085   \n",
       "Edema          0.005843 -0.016123 -0.003993  0.001269       0.015509   \n",
       "Bilirubin      0.062583  0.001208  0.040346  0.020157      -0.009782   \n",
       "Cholesterol    0.023670 -0.013332 -0.031814  0.020435       0.046358   \n",
       "Albumin        1.000000  0.015370  0.001515 -0.039058      -0.001856   \n",
       "Copper         0.015370  1.000000 -0.002676  0.008156       0.034465   \n",
       "Alk_Phos       0.001515 -0.002676  1.000000  0.017881      -0.036749   \n",
       "SGOT          -0.039058  0.008156  0.017881  1.000000       0.013772   \n",
       "Tryglicerides -0.001856  0.034465 -0.036749  0.013772       1.000000   \n",
       "Platelets      0.004874 -0.024679  0.040833  0.059069       0.010085   \n",
       "Prothrombin   -0.012963 -0.052658  0.040108 -0.029069       0.016860   \n",
       "Stage         -0.015126 -0.001518 -0.000170 -0.017251      -0.043826   \n",
       "\n",
       "               Platelets  Prothrombin     Stage  \n",
       "N_Days          0.042913    -0.006062  0.004066  \n",
       "Status          0.003505     0.001908  0.026065  \n",
       "Drug            0.027758    -0.000772  0.000584  \n",
       "Age             0.105258     0.005112 -0.001854  \n",
       "Sex            -0.000127     0.006570 -0.012433  \n",
       "Ascites        -0.018179    -0.007914 -0.016884  \n",
       "Hepatomegaly   -0.020649    -0.022900 -0.004158  \n",
       "Spiders        -0.013254    -0.028451 -0.009396  \n",
       "Edema          -0.014821    -0.003061 -0.008758  \n",
       "Bilirubin      -0.037234    -0.019610 -0.010225  \n",
       "Cholesterol    -0.017935    -0.012795  0.033273  \n",
       "Albumin         0.004874    -0.012963 -0.015126  \n",
       "Copper         -0.024679    -0.052658 -0.001518  \n",
       "Alk_Phos        0.040833     0.040108 -0.000170  \n",
       "SGOT            0.059069    -0.029069 -0.017251  \n",
       "Tryglicerides   0.010085     0.016860 -0.043826  \n",
       "Platelets       1.000000     0.015980 -0.021621  \n",
       "Prothrombin     0.015980     1.000000  0.007317  \n",
       "Stage          -0.021621     0.007317  1.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05946f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=df.isnull().sum().tolist()\n",
    "# b=zip(a,list(df.columns))\n",
    "# b=sorted(b)\n",
    "# b=[element for _,element in b]\n",
    "# print(list(df.columns),b)\n",
    "sorted_null_cols=['Prothrombin', 'Platelets', 'Drug', 'SGOT', 'Copper', 'Ascites', 'Hepatomegaly', 'Alk_Phos', 'Spiders', 'Tryglicerides', 'Cholesterol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "85c610f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N_Days              0\n",
       "Status              0\n",
       "Drug              963\n",
       "Age                 0\n",
       "Sex                 0\n",
       "Ascites          1087\n",
       "Hepatomegaly     1102\n",
       "Spiders          1200\n",
       "Edema               0\n",
       "Bilirubin           0\n",
       "Cholesterol      1435\n",
       "Albumin             0\n",
       "Copper           1006\n",
       "Alk_Phos         1168\n",
       "SGOT              987\n",
       "Tryglicerides    1286\n",
       "Platelets         164\n",
       "Prothrombin        64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67b02fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.copy()\n",
    "df_test=df1.copy()\n",
    "to_drop_cols=['Drug', 'SGOT', 'Copper', 'Ascites', 'Hepatomegaly', 'Alk_Phos', 'Spiders', 'Tryglicerides', 'Cholesterol',\"N_Days\",\"Status\"]\n",
    "df_train=df_train.drop(to_drop_cols,axis=1)\n",
    "df_test=df_test.drop(to_drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f41a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_knn_imputer(df,df1,df2):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    i=1\n",
    "\n",
    "    df_train_imputed=df.copy()\n",
    "    df_test_imputed=df1.copy()\n",
    "    df_val_imputed=df2.copy()\n",
    "    for c in sorted_null_cols:\n",
    "\n",
    "        df_train_train=df_train_imputed[df_train_imputed[c].notnull()]\n",
    "        df_train_test=df_train_imputed[df_train_imputed[c].isnull()]\n",
    "        train_X_train=df_train_train[non_null_cols]\n",
    "        train_y_train=df_train_train.pop(c)\n",
    "        train_X_test=df_train_test[non_null_cols]\n",
    "\n",
    "        test_X=df_test_imputed[df_test_imputed[c].isnull()][non_null_cols]\n",
    "        val_X=df_val_imputed[df_val_imputed[c].isnull()][non_null_cols]\n",
    "        if c in continuous_cols:\n",
    "            print(i,\"co\")\n",
    "            knn=KNeighborsRegressor(n_neighbors=9)\n",
    "            knn.fit(train_X_train,train_y_train)\n",
    "\n",
    "            train_y_pred=knn.predict(train_X_test)\n",
    "            df_train_imputed.loc[df_train_imputed[c].isnull(),c]=train_y_pred\n",
    "\n",
    "            test_y_pred=knn.predict(test_X)\n",
    "            df_test_imputed.loc[df_test_imputed[c].isnull(),c]=test_y_pred\n",
    "            \n",
    "            val_y_pred=knn.predict(val_X)\n",
    "            df_val_imputed.loc[df_val_imputed[c].isnull(),c]=val_y_pred\n",
    "        else:\n",
    "            print(i,\"ca\")\n",
    "            knn=KNeighborsClassifier(n_neighbors=9)\n",
    "            knn.fit(train_X_train,train_y_train)\n",
    "\n",
    "            train_y_pred=knn.predict(train_X_test)\n",
    "            df_train_imputed.loc[df_train_imputed[c].isnull(),c]=train_y_pred\n",
    "\n",
    "            test_y_pred=knn.predict(test_X)\n",
    "            df_test_imputed.loc[df_test_imputed[c].isnull(),c]=test_y_pred\n",
    "            \n",
    "            val_y_pred=knn.predict(val_X)\n",
    "            df_val_imputed.loc[df_val_imputed[c].isnull(),c]=val_y_pred\n",
    "        non_null_cols.append(c)\n",
    "        i+=1\n",
    "    df_train_imputed.isnull().sum()\n",
    "    return df_train_imputed,df_test_imputed,df_val_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffeeb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_simple_imputer(df,df1,df2):\n",
    "    for c in np.setdiff1d(continuous_cols,to_drop_cols):\n",
    "        df[c].fillna(df[c].mean(), inplace=True)\n",
    "        df1[c].fillna(df[c].mean(), inplace=True)\n",
    "        df2[c].fillna(df[c].mean(), inplace=True)\n",
    "    for c in np.setdiff1d(categorical_cols,to_drop_cols):\n",
    "        df[c].fillna(df[c].mode().values[0], inplace=True)\n",
    "        df1[c].fillna(df[c].mode().values[0], inplace=True)\n",
    "        df2[c].fillna(df[c].mode().values[0], inplace=True)\n",
    "    return df,df1,df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3650bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(X_train,X_test,X_val,imputer):\n",
    "\n",
    "    df=X_train.copy()\n",
    "    df1=X_test.copy()\n",
    "    df2=X_val.copy()\n",
    "    \n",
    "    if imputer==\"knn\":\n",
    "        custom_knn_imputer(df,df1,df2)\n",
    "    elif imputer==\"simple\":\n",
    "        custom_simple_imputer(df,df1,df2)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # df[continuous_cols] = scaler.fit_transform(df[continuous_cols]) #train dataset scaling\n",
    "    # df1[continuous_cols] = scaler.transform(df1[continuous_cols]) #test dataset scaling\n",
    "    cols=list(df.columns)\n",
    "#     cols.remove(\"Stage\")\n",
    "#     print(cols)\n",
    "    df[cols] = scaler.fit_transform(df[cols]) #train dataset scaling\n",
    "#     df1[cols] = scaler.transform(df1[cols]) #test dataset scaling\n",
    "#     df2[cols] = scaler.transform(df2[cols]) #test dataset scaling\n",
    "    \n",
    "    return df,df1,df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f4ef2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['Stage'], axis=1)\n",
    "y = df_train.pop('Stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19a4d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_learning_rate\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.50000\n",
      "[1]\tvalidation_0-auc:0.50272\n",
      "[2]\tvalidation_0-auc:0.50553\n",
      "[3]\tvalidation_0-auc:0.51080\n",
      "[4]\tvalidation_0-auc:0.51587\n",
      "[5]\tvalidation_0-auc:0.52175\n",
      "[6]\tvalidation_0-auc:0.51299\n",
      "[7]\tvalidation_0-auc:0.51422\n",
      "[8]\tvalidation_0-auc:0.51024\n",
      "[9]\tvalidation_0-auc:0.50681\n",
      "[10]\tvalidation_0-auc:0.50640\n",
      "[11]\tvalidation_0-auc:0.50365\n",
      "[12]\tvalidation_0-auc:0.49978\n",
      "[13]\tvalidation_0-auc:0.49636\n",
      "[14]\tvalidation_0-auc:0.49625\n",
      "[15]\tvalidation_0-auc:0.49719\n",
      "[16]\tvalidation_0-auc:0.50330\n",
      "[17]\tvalidation_0-auc:0.50860\n",
      "[18]\tvalidation_0-auc:0.50739\n",
      "[19]\tvalidation_0-auc:0.50596\n",
      "[20]\tvalidation_0-auc:0.50441\n",
      "[21]\tvalidation_0-auc:0.50499\n",
      "[22]\tvalidation_0-auc:0.50522\n",
      "[23]\tvalidation_0-auc:0.50382\n",
      "[24]\tvalidation_0-auc:0.50357\n",
      "[25]\tvalidation_0-auc:0.50328\n",
      "[26]\tvalidation_0-auc:0.50398\n",
      "[27]\tvalidation_0-auc:0.50807\n",
      "[28]\tvalidation_0-auc:0.50696\n",
      "[29]\tvalidation_0-auc:0.50658\n",
      "[30]\tvalidation_0-auc:0.50557\n",
      "[31]\tvalidation_0-auc:0.50521\n",
      "[32]\tvalidation_0-auc:0.51067\n",
      "[33]\tvalidation_0-auc:0.51011\n",
      "[34]\tvalidation_0-auc:0.51054\n",
      "[35]\tvalidation_0-auc:0.51113\n",
      "[36]\tvalidation_0-auc:0.50986\n",
      "[37]\tvalidation_0-auc:0.50902\n",
      "[38]\tvalidation_0-auc:0.51036\n",
      "[39]\tvalidation_0-auc:0.51075\n",
      "[40]\tvalidation_0-auc:0.50849\n",
      "[41]\tvalidation_0-auc:0.50964\n",
      "[42]\tvalidation_0-auc:0.50970\n",
      "[43]\tvalidation_0-auc:0.50884\n",
      "[44]\tvalidation_0-auc:0.50839\n",
      "[45]\tvalidation_0-auc:0.50815\n",
      "[46]\tvalidation_0-auc:0.50918\n",
      "[47]\tvalidation_0-auc:0.50802\n",
      "[48]\tvalidation_0-auc:0.50699\n",
      "[49]\tvalidation_0-auc:0.50836\n",
      "[50]\tvalidation_0-auc:0.50853\n",
      "[51]\tvalidation_0-auc:0.50849\n",
      "[52]\tvalidation_0-auc:0.50974\n",
      "[53]\tvalidation_0-auc:0.50636\n",
      "[54]\tvalidation_0-auc:0.50647\n",
      "[55]\tvalidation_0-auc:0.50704\n",
      "0 0.3788099421241042\n",
      "[23:15:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_learning_rate\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.51153\n",
      "[1]\tvalidation_0-auc:0.51153\n",
      "[2]\tvalidation_0-auc:0.49803\n",
      "[3]\tvalidation_0-auc:0.49569\n",
      "[4]\tvalidation_0-auc:0.49699\n",
      "[5]\tvalidation_0-auc:0.49566\n",
      "[6]\tvalidation_0-auc:0.50222\n",
      "[7]\tvalidation_0-auc:0.49120\n",
      "[8]\tvalidation_0-auc:0.49922\n",
      "[9]\tvalidation_0-auc:0.49888\n",
      "[10]\tvalidation_0-auc:0.49397\n",
      "[11]\tvalidation_0-auc:0.49629\n",
      "[12]\tvalidation_0-auc:0.49567\n",
      "[13]\tvalidation_0-auc:0.49391\n",
      "[14]\tvalidation_0-auc:0.49401\n",
      "[15]\tvalidation_0-auc:0.48883\n",
      "[16]\tvalidation_0-auc:0.48966\n",
      "[17]\tvalidation_0-auc:0.49015\n",
      "[18]\tvalidation_0-auc:0.48981\n",
      "[19]\tvalidation_0-auc:0.48960\n",
      "[20]\tvalidation_0-auc:0.48934\n",
      "[21]\tvalidation_0-auc:0.48885\n",
      "[22]\tvalidation_0-auc:0.48907\n",
      "[23]\tvalidation_0-auc:0.48783\n",
      "[24]\tvalidation_0-auc:0.48830\n",
      "[25]\tvalidation_0-auc:0.48989\n",
      "[26]\tvalidation_0-auc:0.49056\n",
      "[27]\tvalidation_0-auc:0.49273\n",
      "[28]\tvalidation_0-auc:0.49345\n",
      "[29]\tvalidation_0-auc:0.49663\n",
      "[30]\tvalidation_0-auc:0.49548\n",
      "[31]\tvalidation_0-auc:0.49559\n",
      "[32]\tvalidation_0-auc:0.49551\n",
      "[33]\tvalidation_0-auc:0.49481\n",
      "[34]\tvalidation_0-auc:0.49590\n",
      "[35]\tvalidation_0-auc:0.49662\n",
      "[36]\tvalidation_0-auc:0.49232\n",
      "[37]\tvalidation_0-auc:0.49334\n",
      "[38]\tvalidation_0-auc:0.49288\n",
      "[39]\tvalidation_0-auc:0.49127\n",
      "[40]\tvalidation_0-auc:0.49044\n",
      "[41]\tvalidation_0-auc:0.48966\n",
      "[42]\tvalidation_0-auc:0.48995\n",
      "[43]\tvalidation_0-auc:0.48999\n",
      "[44]\tvalidation_0-auc:0.49010\n",
      "[45]\tvalidation_0-auc:0.48957\n",
      "[46]\tvalidation_0-auc:0.48974\n",
      "[47]\tvalidation_0-auc:0.48928\n",
      "[48]\tvalidation_0-auc:0.48954\n",
      "[49]\tvalidation_0-auc:0.49021\n",
      "[50]\tvalidation_0-auc:0.48950\n",
      "1 0.35063004823472327\n",
      "[23:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_learning_rate\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.49276\n",
      "[1]\tvalidation_0-auc:0.49312\n",
      "[2]\tvalidation_0-auc:0.49870\n",
      "[3]\tvalidation_0-auc:0.49396\n",
      "[4]\tvalidation_0-auc:0.49571\n",
      "[5]\tvalidation_0-auc:0.50148\n",
      "[6]\tvalidation_0-auc:0.50379\n",
      "[7]\tvalidation_0-auc:0.50458\n",
      "[8]\tvalidation_0-auc:0.50398\n",
      "[9]\tvalidation_0-auc:0.50354\n",
      "[10]\tvalidation_0-auc:0.50338\n",
      "[11]\tvalidation_0-auc:0.50321\n",
      "[12]\tvalidation_0-auc:0.50175\n",
      "[13]\tvalidation_0-auc:0.50177\n",
      "[14]\tvalidation_0-auc:0.49930\n",
      "[15]\tvalidation_0-auc:0.49946\n",
      "[16]\tvalidation_0-auc:0.49991\n",
      "[17]\tvalidation_0-auc:0.49987\n",
      "[18]\tvalidation_0-auc:0.49954\n",
      "[19]\tvalidation_0-auc:0.50006\n",
      "[20]\tvalidation_0-auc:0.50084\n",
      "[21]\tvalidation_0-auc:0.49960\n",
      "[22]\tvalidation_0-auc:0.49963\n",
      "[23]\tvalidation_0-auc:0.50018\n",
      "[24]\tvalidation_0-auc:0.49946\n",
      "[25]\tvalidation_0-auc:0.49935\n",
      "[26]\tvalidation_0-auc:0.49952\n",
      "[27]\tvalidation_0-auc:0.49718\n",
      "[28]\tvalidation_0-auc:0.49663\n",
      "[29]\tvalidation_0-auc:0.49827\n",
      "[30]\tvalidation_0-auc:0.49884\n",
      "[31]\tvalidation_0-auc:0.49959\n",
      "[32]\tvalidation_0-auc:0.49963\n",
      "[33]\tvalidation_0-auc:0.49910\n",
      "[34]\tvalidation_0-auc:0.50006\n",
      "[35]\tvalidation_0-auc:0.49996\n",
      "[36]\tvalidation_0-auc:0.50024\n",
      "[37]\tvalidation_0-auc:0.49893\n",
      "[38]\tvalidation_0-auc:0.49785\n",
      "[39]\tvalidation_0-auc:0.49796\n",
      "[40]\tvalidation_0-auc:0.49937\n",
      "[41]\tvalidation_0-auc:0.49883\n",
      "[42]\tvalidation_0-auc:0.49883\n",
      "[43]\tvalidation_0-auc:0.49881\n",
      "[44]\tvalidation_0-auc:0.49842\n",
      "[45]\tvalidation_0-auc:0.49834\n",
      "[46]\tvalidation_0-auc:0.49892\n",
      "[47]\tvalidation_0-auc:0.49886\n",
      "[48]\tvalidation_0-auc:0.50133\n",
      "[49]\tvalidation_0-auc:0.50129\n",
      "[50]\tvalidation_0-auc:0.50104\n",
      "[51]\tvalidation_0-auc:0.49966\n",
      "[52]\tvalidation_0-auc:0.49940\n",
      "[53]\tvalidation_0-auc:0.49913\n",
      "[54]\tvalidation_0-auc:0.49909\n",
      "[55]\tvalidation_0-auc:0.49848\n",
      "[56]\tvalidation_0-auc:0.49874\n",
      "2 0.36534011729886123\n",
      "[23:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_learning_rate\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.49419\n",
      "[1]\tvalidation_0-auc:0.49364\n",
      "[2]\tvalidation_0-auc:0.48279\n",
      "[3]\tvalidation_0-auc:0.48227\n",
      "[4]\tvalidation_0-auc:0.48599\n",
      "[5]\tvalidation_0-auc:0.48524\n",
      "[6]\tvalidation_0-auc:0.48767\n",
      "[7]\tvalidation_0-auc:0.48700\n",
      "[8]\tvalidation_0-auc:0.48704\n",
      "[9]\tvalidation_0-auc:0.48727\n",
      "[10]\tvalidation_0-auc:0.48770\n",
      "[11]\tvalidation_0-auc:0.48855\n",
      "[12]\tvalidation_0-auc:0.48673\n",
      "[13]\tvalidation_0-auc:0.48853\n",
      "[14]\tvalidation_0-auc:0.48942\n",
      "[15]\tvalidation_0-auc:0.49096\n",
      "[16]\tvalidation_0-auc:0.49011\n",
      "[17]\tvalidation_0-auc:0.49274\n",
      "[18]\tvalidation_0-auc:0.49262\n",
      "[19]\tvalidation_0-auc:0.49360\n",
      "[20]\tvalidation_0-auc:0.49506\n",
      "[21]\tvalidation_0-auc:0.49774\n",
      "[22]\tvalidation_0-auc:0.49666\n",
      "[23]\tvalidation_0-auc:0.49770\n",
      "[24]\tvalidation_0-auc:0.49778\n",
      "[25]\tvalidation_0-auc:0.49709\n",
      "[26]\tvalidation_0-auc:0.49697\n",
      "[27]\tvalidation_0-auc:0.49691\n",
      "[28]\tvalidation_0-auc:0.49646\n",
      "[29]\tvalidation_0-auc:0.49626\n",
      "[30]\tvalidation_0-auc:0.49601\n",
      "[31]\tvalidation_0-auc:0.49444\n",
      "[32]\tvalidation_0-auc:0.49534\n",
      "[33]\tvalidation_0-auc:0.49510\n",
      "[34]\tvalidation_0-auc:0.49230\n",
      "[35]\tvalidation_0-auc:0.49166\n",
      "[36]\tvalidation_0-auc:0.49180\n",
      "[37]\tvalidation_0-auc:0.49230\n",
      "[38]\tvalidation_0-auc:0.49168\n",
      "[39]\tvalidation_0-auc:0.49323\n",
      "[40]\tvalidation_0-auc:0.49367\n",
      "[41]\tvalidation_0-auc:0.49357\n",
      "[42]\tvalidation_0-auc:0.49393\n",
      "[43]\tvalidation_0-auc:0.49344\n",
      "[44]\tvalidation_0-auc:0.49386\n",
      "[45]\tvalidation_0-auc:0.49500\n",
      "[46]\tvalidation_0-auc:0.49440\n",
      "[47]\tvalidation_0-auc:0.49443\n",
      "[48]\tvalidation_0-auc:0.49638\n",
      "[49]\tvalidation_0-auc:0.49604\n",
      "[50]\tvalidation_0-auc:0.49614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\tvalidation_0-auc:0.49700\n",
      "[52]\tvalidation_0-auc:0.49699\n",
      "[53]\tvalidation_0-auc:0.49561\n",
      "[54]\tvalidation_0-auc:0.49545\n",
      "[55]\tvalidation_0-auc:0.49694\n",
      "[56]\tvalidation_0-auc:0.49675\n",
      "[57]\tvalidation_0-auc:0.49753\n",
      "[58]\tvalidation_0-auc:0.49787\n",
      "[59]\tvalidation_0-auc:0.49913\n",
      "[60]\tvalidation_0-auc:0.49910\n",
      "[61]\tvalidation_0-auc:0.49916\n",
      "[62]\tvalidation_0-auc:0.49902\n",
      "[63]\tvalidation_0-auc:0.49857\n",
      "[64]\tvalidation_0-auc:0.49785\n",
      "[65]\tvalidation_0-auc:0.49856\n",
      "[66]\tvalidation_0-auc:0.49827\n",
      "[67]\tvalidation_0-auc:0.49816\n",
      "[68]\tvalidation_0-auc:0.49845\n",
      "[69]\tvalidation_0-auc:0.49895\n",
      "[70]\tvalidation_0-auc:0.49873\n",
      "[71]\tvalidation_0-auc:0.49873\n",
      "[72]\tvalidation_0-auc:0.49841\n",
      "[73]\tvalidation_0-auc:0.49897\n",
      "[74]\tvalidation_0-auc:0.49894\n",
      "[75]\tvalidation_0-auc:0.49925\n",
      "[76]\tvalidation_0-auc:0.49935\n",
      "[77]\tvalidation_0-auc:0.49934\n",
      "[78]\tvalidation_0-auc:0.49932\n",
      "[79]\tvalidation_0-auc:0.49929\n",
      "[80]\tvalidation_0-auc:0.49964\n",
      "[81]\tvalidation_0-auc:0.49967\n",
      "[82]\tvalidation_0-auc:0.50004\n",
      "[83]\tvalidation_0-auc:0.50013\n",
      "[84]\tvalidation_0-auc:0.50013\n",
      "[85]\tvalidation_0-auc:0.50015\n",
      "[86]\tvalidation_0-auc:0.50051\n",
      "[87]\tvalidation_0-auc:0.50051\n",
      "[88]\tvalidation_0-auc:0.50042\n",
      "[89]\tvalidation_0-auc:0.50080\n",
      "[90]\tvalidation_0-auc:0.50060\n",
      "[91]\tvalidation_0-auc:0.50058\n",
      "[92]\tvalidation_0-auc:0.50093\n",
      "[93]\tvalidation_0-auc:0.50065\n",
      "[94]\tvalidation_0-auc:0.50089\n",
      "[95]\tvalidation_0-auc:0.50143\n",
      "[96]\tvalidation_0-auc:0.50099\n",
      "[97]\tvalidation_0-auc:0.50121\n",
      "[98]\tvalidation_0-auc:0.50119\n",
      "[99]\tvalidation_0-auc:0.50030\n",
      "[100]\tvalidation_0-auc:0.50113\n",
      "[101]\tvalidation_0-auc:0.50121\n",
      "[102]\tvalidation_0-auc:0.50150\n",
      "[103]\tvalidation_0-auc:0.50170\n",
      "[104]\tvalidation_0-auc:0.50173\n",
      "[105]\tvalidation_0-auc:0.50162\n",
      "[106]\tvalidation_0-auc:0.50135\n",
      "[107]\tvalidation_0-auc:0.50136\n",
      "[108]\tvalidation_0-auc:0.50136\n",
      "[109]\tvalidation_0-auc:0.50182\n",
      "[110]\tvalidation_0-auc:0.50097\n",
      "[111]\tvalidation_0-auc:0.50008\n",
      "[112]\tvalidation_0-auc:0.50027\n",
      "[113]\tvalidation_0-auc:0.50038\n",
      "[114]\tvalidation_0-auc:0.50035\n",
      "[115]\tvalidation_0-auc:0.50109\n",
      "[116]\tvalidation_0-auc:0.50023\n",
      "[117]\tvalidation_0-auc:0.50049\n",
      "[118]\tvalidation_0-auc:0.50300\n",
      "[119]\tvalidation_0-auc:0.50351\n",
      "[120]\tvalidation_0-auc:0.50264\n",
      "[121]\tvalidation_0-auc:0.50260\n",
      "[122]\tvalidation_0-auc:0.50246\n",
      "[123]\tvalidation_0-auc:0.50276\n",
      "[124]\tvalidation_0-auc:0.49856\n",
      "[125]\tvalidation_0-auc:0.49856\n",
      "[126]\tvalidation_0-auc:0.49894\n",
      "[127]\tvalidation_0-auc:0.49873\n",
      "[128]\tvalidation_0-auc:0.50003\n",
      "[129]\tvalidation_0-auc:0.49977\n",
      "[130]\tvalidation_0-auc:0.49984\n",
      "[131]\tvalidation_0-auc:0.50342\n",
      "[132]\tvalidation_0-auc:0.50335\n",
      "[133]\tvalidation_0-auc:0.50329\n",
      "[134]\tvalidation_0-auc:0.50384\n",
      "[135]\tvalidation_0-auc:0.50392\n",
      "[136]\tvalidation_0-auc:0.50374\n",
      "[137]\tvalidation_0-auc:0.50375\n",
      "[138]\tvalidation_0-auc:0.50395\n",
      "[139]\tvalidation_0-auc:0.50402\n",
      "[140]\tvalidation_0-auc:0.50483\n",
      "[141]\tvalidation_0-auc:0.50537\n",
      "[142]\tvalidation_0-auc:0.50536\n",
      "[143]\tvalidation_0-auc:0.50434\n",
      "[144]\tvalidation_0-auc:0.50420\n",
      "[145]\tvalidation_0-auc:0.50113\n",
      "[146]\tvalidation_0-auc:0.50115\n",
      "[147]\tvalidation_0-auc:0.50099\n",
      "[148]\tvalidation_0-auc:0.50036\n",
      "[149]\tvalidation_0-auc:0.50045\n",
      "3 0.3558458001847389\n",
      "[23:16:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"n_learning_rate\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.53125\n",
      "[1]\tvalidation_0-auc:0.52473\n",
      "[2]\tvalidation_0-auc:0.52006\n",
      "[3]\tvalidation_0-auc:0.52241\n",
      "[4]\tvalidation_0-auc:0.51994\n",
      "[5]\tvalidation_0-auc:0.51891\n",
      "[6]\tvalidation_0-auc:0.51321\n",
      "[7]\tvalidation_0-auc:0.51377\n",
      "[8]\tvalidation_0-auc:0.51043\n",
      "[9]\tvalidation_0-auc:0.50908\n",
      "[10]\tvalidation_0-auc:0.50870\n",
      "[11]\tvalidation_0-auc:0.50764\n",
      "[12]\tvalidation_0-auc:0.50844\n",
      "[13]\tvalidation_0-auc:0.50880\n",
      "[14]\tvalidation_0-auc:0.50770\n",
      "[15]\tvalidation_0-auc:0.50531\n",
      "[16]\tvalidation_0-auc:0.50612\n",
      "[17]\tvalidation_0-auc:0.49851\n",
      "[18]\tvalidation_0-auc:0.49992\n",
      "[19]\tvalidation_0-auc:0.50043\n",
      "[20]\tvalidation_0-auc:0.49700\n",
      "[21]\tvalidation_0-auc:0.49676\n",
      "[22]\tvalidation_0-auc:0.49704\n",
      "[23]\tvalidation_0-auc:0.49692\n",
      "[24]\tvalidation_0-auc:0.49904\n",
      "[25]\tvalidation_0-auc:0.49909\n",
      "[26]\tvalidation_0-auc:0.49652\n",
      "[27]\tvalidation_0-auc:0.49862\n",
      "[28]\tvalidation_0-auc:0.49837\n",
      "[29]\tvalidation_0-auc:0.49638\n",
      "[30]\tvalidation_0-auc:0.49623\n",
      "[31]\tvalidation_0-auc:0.49497\n",
      "[32]\tvalidation_0-auc:0.49465\n",
      "[33]\tvalidation_0-auc:0.49361\n",
      "[34]\tvalidation_0-auc:0.49392\n",
      "[35]\tvalidation_0-auc:0.49437\n",
      "[36]\tvalidation_0-auc:0.49376\n",
      "[37]\tvalidation_0-auc:0.49385\n",
      "[38]\tvalidation_0-auc:0.49527\n",
      "[39]\tvalidation_0-auc:0.49517\n",
      "[40]\tvalidation_0-auc:0.49448\n",
      "[41]\tvalidation_0-auc:0.49642\n",
      "[42]\tvalidation_0-auc:0.49538\n",
      "[43]\tvalidation_0-auc:0.49536\n",
      "[44]\tvalidation_0-auc:0.49595\n",
      "[45]\tvalidation_0-auc:0.49526\n",
      "[46]\tvalidation_0-auc:0.49470\n",
      "[47]\tvalidation_0-auc:0.49461\n",
      "[48]\tvalidation_0-auc:0.49463\n",
      "[49]\tvalidation_0-auc:0.49461\n",
      "[50]\tvalidation_0-auc:0.49404\n",
      "4 0.35063004823472327\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "skf=model_selection.StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "preds=[]\n",
    "val_score=[]\n",
    "for fold, (train_indices, valid_indices) in enumerate(skf.split(X,y)):\n",
    "    \n",
    "    X_train=X.iloc[train_indices]\n",
    "    y_train=y.iloc[train_indices]\n",
    "    X_val=X.iloc[valid_indices]\n",
    "    y_val=y.iloc[valid_indices]\n",
    "    X_test=df_test.copy()\n",
    "\n",
    "    X_train,X_test,X_val=pre_process(X_train,X_test,X_val,\"simple\")\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    model = XGBClassifier(n_learning_rate=0.75, max_depth=3,eval_metric='auc',n_estimators=150 ,random_state=fold, gamma=0,verbose=10000)\n",
    "    model.fit(X_train, y_train,early_stopping_rounds=50,eval_set=[(X_val,y_val)])\n",
    "\n",
    "    preds_val = model.predict(X_val)\n",
    "    score=f1_score(y_val,preds_val,average =\"weighted\")\n",
    "    val_score.append(score)\n",
    "    print(fold,score)\n",
    "\n",
    "    preds_test=model.predict_proba(X_test)\n",
    "    preds.append(preds_test)\n",
    "fscore=np.mean(np.array(val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ee2858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36025119121543014\n"
     ]
    }
   ],
   "source": [
    "print(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b047b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.mean(preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49fd8dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15006268 0.18850127 0.27098897 0.39044708]\n",
      " [0.14580293 0.18723398 0.2486262  0.41833687]\n",
      " [0.1462265  0.1857442  0.26778668 0.40024263]\n",
      " ...\n",
      " [0.15029821 0.19054571 0.30083296 0.35832316]\n",
      " [0.15782717 0.21507688 0.3261164  0.30097955]\n",
      " [0.1457203  0.18576738 0.26798788 0.40052444]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7af091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_=np.argmax(p,axis=1)\n",
    "p_=p_+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8485c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame(p_)\n",
    "res.index = df_test.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "res.columns = [\"Stage\"]\n",
    "res.to_csv(\"prediction_results102.csv\", index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48824218",
   "metadata": {},
   "source": [
    "### submission successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "385d45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some models I tried based on unbalaced nature of data but did give good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "771f47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model1():\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    model = XGBClassifier(learning_rate=0.75, max_depth=3, random_state=42, gamma=0, eval_metric='error')\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    res = pd.DataFrame(predictions) #preditcions are nothing but the final predictions of your model on input features of your new unseen test data\n",
    "    res.index = df_test.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "    res.columns = [\"Stage\"]\n",
    "    res.to_csv(\"prediction_results101.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2220753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model2():\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.utils import class_weight\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    model = XGBClassifier(learning_rate=0.75, max_depth=3, random_state=1, gamma=0, eval_metric='error')\n",
    "    model.fit(X_train, y_train,sample_weight=classes_weights)\n",
    "    predictions = model.predict(X_test)\n",
    "    res = pd.DataFrame(predictions) #preditcions are nothing but the final predictions of your model on input features of your new unseen test data\n",
    "    res.index = df_test.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "    res.columns = [\"Stage\"]\n",
    "    res.to_csv(\"prediction_results101.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "673901d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model3():\n",
    "    from xgboost import XGBClassifier\n",
    "    from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "    model=BalancedBaggingClassifier(base_estimator=XGBClassifier(learning_rate=0.75, max_depth=3, random_state=1, gamma=0, eval_metric='error'),\n",
    "                                sampling_strategy='not majority',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    res = pd.DataFrame(predictions) #preditcions are nothing but the final predictions of your model on input features of your new unseen test data\n",
    "    res.index = df_test.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "    res.columns = [\"Stage\"]\n",
    "    res.to_csv(\"prediction_results101.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05d651f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model4():\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    weights = y_train.value_counts()/len(df)\n",
    "    \n",
    "    model = XGBClassifier(learning_rate=0.75, max_depth=3, random_state=1, gamma=0, eval_metric='error',class_weight=weights)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    res = pd.DataFrame(predictions) #preditcions are nothing but the final predictions of your model on input features of your new unseen test data\n",
    "    res.index = df_test.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "    res.columns = [\"Stage\"]\n",
    "    res.to_csv(\"prediction_results101.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba17fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model5(X_train,y_train,X_test):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    oversample = SMOTE()\n",
    "    X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "    \n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    model = XGBClassifier(learning_rate=0.75, max_depth=3, random_state=1, gamma=0, eval_metric='error')\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    res = pd.DataFrame(predictions) #preditcions are nothing but the final predictions of your model on input features of your new unseen test data\n",
    "    res.index = df_test.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "    res.columns = [\"Stage\"]\n",
    "    res.to_csv(\"prediction_results101.csv\", index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
